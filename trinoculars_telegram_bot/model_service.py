import logging
import os
from typing import Dict, Optional, Tuple

from .config import TRINOCULARS_PATH, MODEL_TYPE, MODEL_DIR, USE_BINOCULARS

# Import Trinoculars modules (paths are prepared in config)
from model_utils import load_model, classify_text  # type: ignore
from text_analysis import analyze_text  # type: ignore
from binoculars_utils import (  # type: ignore
    initialize_binoculars,
    compute_scores as _compute_scores,
)

logger = logging.getLogger(__name__)

# Global model state (loaded once at startup)
_model = None
_scaler = None
_label_encoder = None
_imputer = None

_bino_chat = None
_bino_coder = None


def load_detection_model(
    model_type: Optional[str] = None,
    model_dir: Optional[str] = None,
) -> bool:
    global _model, _scaler, _label_encoder, _imputer

    model_type = model_type or MODEL_TYPE
    model_dir = model_dir or MODEL_DIR

    logger.info(
        "Loading Trinoculars model (type=%s, dir=%s) from %s",
        model_type,
        model_dir,
        TRINOCULARS_PATH,
    )

    original_cwd = os.getcwd()
    try:
        os.chdir(str(TRINOCULARS_PATH))
        _model, _scaler, _label_encoder, _imputer = load_model(
            model_type=model_type,
            model_dir=model_dir,
        )
        logger.info("Trinoculars model loaded successfully")

        # Optionally initialize Binoculars observers
        if USE_BINOCULARS:
            _initialize_binoculars_if_needed()

        return True
    except Exception as e:
        logger.exception("Error loading Trinoculars model: %s", e)
        _model = _scaler = _label_encoder = _imputer = None
        return False
    finally:
        os.chdir(original_cwd)


def is_model_ready() -> bool:
    return _model is not None


def _initialize_binoculars_if_needed() -> None:
    global _bino_chat, _bino_coder

    if _bino_chat is not None or _bino_coder is not None:
        return

    try:
        logger.info("Initializing Binoculars models (this may take a while)...")
        _bino_chat, _bino_coder = initialize_binoculars()
        logger.info("Binoculars initialized.")
    except Exception as e:
        logger.exception("Failed to initialize Binoculars: %s", e)
        _bino_chat = _bino_coder = None


def classify_user_text(
    text: str,
    use_scores: bool = False,
) -> Dict:
    if not is_model_ready():
        raise RuntimeError("Model is not loaded")

    scores: Optional[Dict] = None
    if use_scores:
        _initialize_binoculars_if_needed()
        if _bino_chat is not None or _bino_coder is not None:
            scores = _compute_scores(text, _bino_chat, _bino_coder)

    # We don't change CWD here because model_utils works with already loaded objects
    result = classify_text(
        text,
        model=_model,
        scaler=_scaler,
        label_encoder=_label_encoder,
        imputer=_imputer,
        scores=scores,
    )
    return result


def analyze_user_text(text: str) -> Dict:
    return analyze_text(text)


def format_classification_result(result: Dict) -> str:
    predicted_class = result["predicted_class"]
    probabilities = result["probabilities"]

    # Basic mapping for Russian UI; adjust class name checks if needed
    cls_str = str(predicted_class).lower()
    if "human" in cls_str or "—á–µ–ª–æ–≤–µ–∫" in cls_str:
        emoji = "‚úÖ"
        status = "–ß–ï–õ–û–í–ï–ö"
        color_info = "–¢–µ–∫—Å—Ç, –≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–∞–ø–∏—Å–∞–Ω —á–µ–ª–æ–≤–µ–∫–æ–º"
    else:
        emoji = "ü§ñ"
        status = "–ò–°–ö–£–°–°–¢–í–ï–ù–ù–´–ô –ò–ù–¢–ï–õ–õ–ï–ö–¢"
        color_info = "–¢–µ–∫—Å—Ç, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ò–ò"

    message = f"{emoji} <b>–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</b>\n\n"
    message += f"<b>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å:</b> {status}\n\n"
    message += "<b>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤:</b>\n"

    for cls, prob in probabilities.items():
        name = str(cls)
        percentage = prob * 100
        bar_len = int(percentage / 5)  # up to ~20 symbols
        bar = "‚ñà" * bar_len + "‚ñë" * (20 - bar_len)
        message += f"{name}: {percentage:.1f}% {bar}\n"

    message += f"\n<i>{color_info}</i>"
    return message


def format_stats(analysis: Dict) -> str:
    basic = analysis.get("basic_stats", {})
    diversity = analysis.get("lexical_diversity", {})
    structure = analysis.get("text_structure", {})
    readability = analysis.get("readability", {})

    text = "<b>–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞</b>\n\n"

    text += "<b>–û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</b>\n"
    text += f"–¢–æ–∫–µ–Ω–æ–≤: {basic.get('total_tokens', 0)}\n"
    text += f"–°–ª–æ–≤: {basic.get('total_words', 0)}\n"
    text += f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {basic.get('unique_words', 0)}\n"
    text += f"–°—Ç–æ–ø-—Å–ª–æ–≤: {basic.get('stop_words', 0)}\n"
    avg_len = basic.get("avg_word_length", 0.0)
    text += f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞: {avg_len:.2f} —Å–∏–º–≤–æ–ª–æ–≤\n\n"

    text += "<b>–õ–µ–∫—Å–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ:</b>\n"
    ttr = diversity.get("ttr", 0.0)
    mtld = diversity.get("mtld", 0.0)
    text += f"TTR (–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫ —Ç–æ–∫–µ–Ω–∞–º): {ttr:.3f}\n"
    text += f"MTLD (–º–µ—Ä–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è): {mtld:.2f}\n\n"

    text += "<b>–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ–∫—Å—Ç–∞:</b>\n"
    text += f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {structure.get('sentence_count', 0)}\n"
    avg_sent = structure.get("avg_sentence_length", 0.0)
    text += f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {avg_sent:.2f} —Ç–æ–∫–µ–Ω–æ–≤\n\n"

    text += "<b>–ß–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å:</b>\n"
    fk = readability.get("flesh_kincaid_score", 0.0)
    wps = readability.get("words_per_sentence", 0.0)
    text += f"–ò–Ω–¥–µ–∫—Å –§–ª–µ—à–∞-–ö–∏–Ω–∫–µ–π–¥–∞: {fk:.2f}\n"
    text += f"–°–ª–æ–≤ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {wps:.2f}\n"

    return text


